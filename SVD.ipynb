{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFNlNlRCpuL8",
        "outputId": "3752ad4f-6ffc-4225-9660-3442e06395d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Random Split\n",
            "Random Split RMSE: 2.7279\n",
            "Random Split Precision: 0.7633\n",
            "Random Split Recall: 0.3851\n",
            "Random Split F1-Score: 0.2143\n",
            "\n",
            "Top recommendations for user 2:\n",
            "\n",
            "Original ratings for user 2:\n",
            "     movieId  rating\n",
            "242    68157     4.5\n",
            "237     8798     3.5\n",
            "248    80906     5.0\n",
            "245    77455     3.0\n",
            "251    91529     3.5\n",
            "\n",
            "Evaluating Temporal Split\n",
            "Temporal Split RMSE: 2.8761\n",
            "Temporal Split Precision: 0.1062\n",
            "Temporal Split Recall: 0.3260\n",
            "Temporal Split F1-Score: 0.1603\n",
            "\n",
            "Top recommendations for user 2:\n",
            "\n",
            "Original ratings for user 2:\n",
            "     movieId  rating\n",
            "232      318     3.0\n",
            "246    79132     4.0\n",
            "260   131724     5.0\n",
            "258   115713     3.5\n",
            "253    99114     3.5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import mean_squared_error, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import sqrt\n",
        "\n",
        "CHUNK_SIZE = 20000\n",
        "N_COMPONENTS = 10\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "def load_dataset(file_path):\n",
        "\n",
        "    chunks = []\n",
        "    for chunk in pd.read_csv(file_path, chunksize=CHUNK_SIZE):\n",
        "        chunks.append(chunk)\n",
        "    return pd.concat(chunks)\n",
        "\n",
        "def create_user_movie_matrix(df):\n",
        "\n",
        "    return df.pivot_table(index='userId', columns='movieId', values='rating', fill_value=0)\n",
        "\n",
        "def preprocess_splits(train_df, test_df):\n",
        "\n",
        "    train_matrix = create_user_movie_matrix(train_df)\n",
        "    test_matrix = create_user_movie_matrix(test_df)\n",
        "\n",
        "    common_users = train_matrix.index.intersection(test_matrix.index)\n",
        "    common_movies = train_matrix.columns.intersection(test_matrix.columns)\n",
        "\n",
        "    return (\n",
        "        train_matrix.loc[common_users, common_movies],\n",
        "        test_matrix.loc[common_users, common_movies]\n",
        "    )\n",
        "\n",
        "def normalize_predictions(reconstructed, ratings):\n",
        "\n",
        "    min_rating, max_rating = ratings['rating'].min(), ratings['rating'].max()\n",
        "    return (reconstructed - reconstructed.min()) / (reconstructed.max() - reconstructed.min()) * (max_rating - min_rating) + min_rating\n",
        "\n",
        "def train_svd(matrix):\n",
        "\n",
        "    svd = TruncatedSVD(n_components=N_COMPONENTS, random_state=RANDOM_STATE)\n",
        "    U = svd.fit_transform(matrix)\n",
        "    Sigma = svd.singular_values_\n",
        "    VT = svd.components_\n",
        "    return U, Sigma, VT\n",
        "\n",
        "def reconstruct_matrix(U, Sigma, VT, ratings):\n",
        "\n",
        "    reconstructed = np.dot(U, np.dot(np.diag(Sigma), VT))\n",
        "    return normalize_predictions(reconstructed, ratings)\n",
        "\n",
        "def evaluate_predictions(true_matrix, pred_matrix):\n",
        "\n",
        "    mask = np.array(true_matrix).flatten() != 0\n",
        "    true_flat = np.array(true_matrix).flatten()[mask]\n",
        "    pred_flat = pred_matrix.flatten()[mask]\n",
        "\n",
        "    rmse = sqrt(mean_squared_error(true_flat, pred_flat))\n",
        "\n",
        "    threshold = 3.5\n",
        "    true_binary = (true_flat >= threshold).astype(int)\n",
        "    pred_binary = (pred_flat >= threshold).astype(int)\n",
        "\n",
        "    precision = precision_score(true_binary, pred_binary, zero_division=0, average='weighted')\n",
        "    recall = recall_score(true_binary, pred_binary, zero_division=0, average='weighted')\n",
        "    f1 = f1_score(true_binary, pred_binary, zero_division=0, average='weighted')\n",
        "\n",
        "    return rmse, precision, recall, f1\n",
        "\n",
        "def recommend_movies(user_id, pred_matrix, user_mapper, movie_mapper, top_n=5):\n",
        "\n",
        "    if user_id not in user_mapper:\n",
        "        return []\n",
        "\n",
        "    user_idx = user_mapper.get_loc(user_id)\n",
        "    user_ratings = pred_matrix[user_idx]\n",
        "\n",
        "    unrated_mask = np.array(pred_matrix[user_idx]) == 0\n",
        "    unrated_movie_indices = np.where(unrated_mask)[0]\n",
        "\n",
        "    recommendations = []\n",
        "    for idx in unrated_movie_indices:\n",
        "        movie_id = movie_mapper[idx]\n",
        "        recommendations.append((movie_id, user_ratings[idx]))\n",
        "\n",
        "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "    return recommendations[:top_n]\n",
        "\n",
        "def main():\n",
        "\n",
        "    ratings = load_dataset('ml-latest-small/ratings.csv')\n",
        "\n",
        "    train_random, test_random = train_test_split(ratings, test_size=0.2, random_state=RANDOM_STATE)\n",
        "    ratings_sorted = ratings.sort_values('timestamp')\n",
        "    cutoff = ratings_sorted['timestamp'].quantile(0.8)\n",
        "    train_temporal = ratings_sorted[ratings_sorted['timestamp'] <= cutoff]\n",
        "    test_temporal = ratings_sorted[ratings_sorted['timestamp'] > cutoff]\n",
        "\n",
        "\n",
        "    for split_type, train_df, test_df in [('Random', train_random, test_random), ('Temporal', train_temporal, test_temporal)]:\n",
        "        print(f\"\\nEvaluating {split_type} Split\")\n",
        "\n",
        "\n",
        "        train_matrix, test_matrix = preprocess_splits(train_df, test_df)\n",
        "\n",
        "        U, Sigma, VT = train_svd(train_matrix)\n",
        "\n",
        "        pred_matrix = reconstruct_matrix(U, Sigma, VT, train_df)\n",
        "\n",
        "\n",
        "        rmse, precision, recall, f1 = evaluate_predictions(test_matrix, pred_matrix)\n",
        "        print(f\"{split_type} Split RMSE: {rmse:.4f}\")\n",
        "        print(f\"{split_type} Split Precision: {precision:.4f}\")\n",
        "        print(f\"{split_type} Split Recall: {recall:.4f}\")\n",
        "        print(f\"{split_type} Split F1-Score: {f1:.4f}\")\n",
        "\n",
        "        user_id = 2\n",
        "        user_mapper = train_matrix.index\n",
        "        movie_mapper = train_matrix.columns\n",
        "\n",
        "        recommendations = recommend_movies(user_id, pred_matrix, user_mapper, movie_mapper)\n",
        "        print(f\"\\nTop recommendations for user {user_id}:\")\n",
        "        for movie_id, rating in recommendations:\n",
        "            print(f\"Movie ID: {movie_id}, Predicted Rating: {rating:.2f}\")\n",
        "\n",
        "        print(f\"\\nOriginal ratings for user {user_id}:\")\n",
        "        print(train_df[train_df['userId'] == user_id][['movieId', 'rating']].head())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ofLPhR-cpRRg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}